{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b57f1b",
   "metadata": {},
   "source": [
    "# `train_colab.ipynb` — Hard Hat (Helmet) Detection (YOLOv8)\n",
    "\n",
    "\n",
    "**Bu notebook Colab üzerinde çalıştırılmak üzere hazırlandı.** Amacımız: kendi video/görüntü veri setini kullanarak bir **kask (helmet) / no_helmet** (kasksız) tespit modeli eğitmek, **en iyi ağırlığı (`best.pt`)** elde etmek ve bunu **ONNX** formatına dışa aktarmaktır. Notebook adım adım:\n",
    "\n",
    "1. Ortam kurulumu (Ultralytics YOLOv8 + ONNX)\n",
    "2. Veri seti yapısı ve etiket formatı (YOLO format)\n",
    "3. Veri yükleme / Drive bağlama / klasör hazırlama\n",
    "4. Eğitim (transfer learning — yolov8n ile başlama)\n",
    "5. Değerlendirme ve görselleştirme\n",
    "6. Model dışa aktarma (ONNX) ve quantizasyon (opsiyonel)\n",
    "7. Eğitilmiş ağırlıkları indirme\n",
    "\n",
    "> Not: Colab runtime'ında `Runtime > Change runtime type` menüsünden **GPU (CUDA)** seçmen eğitim hızını önemli oranda artırır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Ortam kurulumu — Bu hücreyi çalıştırın (Colab'da)\n",
    "!pip install -U ultralytics onnx onnxruntime -q\n",
    "\n",
    "# Kısa bir bilgi satırı\n",
    "import ultralytics, onnx, onnxruntime, sys\n",
    "print('ultralytics', ultralytics.__version__)\n",
    "print('onnx', onnx.__version__)\n",
    "print('onnxruntime', onnxruntime.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa86fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) GPU kontrolü ve device seçimi\n",
    "import torch, os\n",
    "print('torch', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        print('GPU name:', torch.cuda.get_device_name(0))\n",
    "    except:\n",
    "        pass\n",
    "# device: 0 for GPU, 'cpu' otherwise — ultralytics accepts both\n",
    "device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device =', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1f7774",
   "metadata": {},
   "source": [
    "## Veri seti yapısı ve etiket formatı (YOLO format)\n",
    "\n",
    "\n",
    "Eğitim için en kolay ve yaygın format **YOLO (txt)** formatıdır. Dizilim aşağıdaki gibi olmalıdır:\n",
    "\n",
    "```\n",
    "/dataset/\n",
    "  /train/\n",
    "    /images/\n",
    "      img001.jpg\n",
    "      img002.jpg\n",
    "    /labels/\n",
    "      img001.txt\n",
    "      img002.txt\n",
    "  /val/\n",
    "    /images/\n",
    "    /labels/\n",
    "```\n",
    "\n",
    "Her `*.txt` dosyası için satırlar şu formatta olmalı (normalleştirilmiş koordinatlar):\n",
    "\n",
    "```\n",
    "<class_id> <x_center> <y_center> <width> <height>\n",
    "```\n",
    "\n",
    "Tüm sayılar `0..1` aralığında normalize edilmiş olmalı (x_center, y_center, width, height). Örnek:\n",
    "\n",
    "```\n",
    "# örnek: class 0 = helmet, class 1 = no_helmet\n",
    "0 0.5123 0.4132 0.2345 0.3210\n",
    "```\n",
    "\n",
    "**Sınıf isimlerini** bir `data.yaml` dosyasında tanımlayacağız (aşağıda oluşturacağız).\n",
    "\n",
    "> Öneri: Annotasyon için LabelImg, CVAT veya Roboflow kullanabilirsiniz. Roboflow etiketleme, augmentasyon ve export işlemlerini kolaylaştırır. LabelImg ile YOLO formatında kayıt alabilirsiniz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45408076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Örnek klasör iskeleti oluştur (gerekirse). Gerçek verinizi buraya yükleyin veya Google Drive'a koyun.\n",
    "import os\n",
    "os.makedirs('/content/dataset/train/images', exist_ok=True)\n",
    "os.makedirs('/content/dataset/train/labels', exist_ok=True)\n",
    "os.makedirs('/content/dataset/val/images', exist_ok=True)\n",
    "os.makedirs('/content/dataset/val/labels', exist_ok=True)\n",
    "print('Dataset klasörleri oluşturuldu: /content/dataset/...')\n",
    "print('NOT: Gerçek görüntü ve label dosyalarınızı yukarıdaki klasörlere yükleyin (Colab upload veya Drive mount).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665e5ad4",
   "metadata": {},
   "source": [
    "### Google Drive'a bağlanmak (opsiyonel)\n",
    "\n",
    "Eğer veri setinizi Google Drive'da saklıyorsanız, aşağıdaki hücre ile Drive'ı mount edebilirsiniz. Bu, büyük veri setleriyle çalışırken pratiktir.\n",
    "\n",
    "> `Mount` sonrası Drive içindeki yolu (ör. `/content/drive/MyDrive/datasets/myhardhat/`) `data.yaml`'da kullanabilirsiniz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee1cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drive'a bağlan (opsiyonel) — sadece isterseniz çalıştırın\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print('Drive mounted: /content/drive')\n",
    "except Exception as e:\n",
    "    print('Drive mount çalıştırılmadı veya bu ortam Colab değil:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d0b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) data.yaml oluştur (YOLOv8 için). Sınıf isimlerini ihtiyacınıza göre güncelleyin.\n",
    "import yaml\n",
    "data = {\n",
    "    'train': '/content/dataset/train/images',\n",
    "    'val': '/content/dataset/val/images',\n",
    "    'names': ['helmet', 'no_helmet']\n",
    "}\n",
    "with open('data.yaml', 'w') as f:\n",
    "    yaml.dump(data, f)\n",
    "print('data.yaml oluşturuldu:')\n",
    "print(open('data.yaml').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Eğitim — Transfer learning ile yolov8n (küçük/nano) modeliyle başlamak hızlı sonuç verir.\n",
    "# Aşağıdaki parametreleri dataset boyutuna ve Colab GPU belleğine göre ayarlayın.\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# model seçimi: 'yolov8n.pt' (nano), 'yolov8s.pt' (small) vs 'yolov8m.pt' etc.\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Önemli parametreler:\n",
    "# epochs: eğitim epoch sayısı (başlangıç 30-100 arası deneyin)\n",
    "# imgsz: input boyutu (640 yaygın, 480 daha hızlı)\n",
    "# batch: GPU belleğinize göre ayarlayın (ör: 16, 8, 4)\n",
    "# device: 0 (GPU) veya 'cpu'\n",
    "\n",
    "model.train(\n",
    "    data='data.yaml',\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    workers=4,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Eğitim tamamlandığında sonuçlar runs/train/ altında olacak; en iyi ağırlık genelde runs/train/exp/weights/best.pt\n",
    "print('Eğitim tamamlandı — runs/train/ klasörünü kontrol edin.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d14e2",
   "metadata": {},
   "source": [
    "### Eğitim ipuçları ve hiperparametreler\n",
    "\n",
    "- **epochs**: Küçük datasetler için 30-100 arası; büyük datasetler için daha yüksek. Başlangıçta 50 iyi bir denemedir.\n",
    "- **batch**: GPU belleğine göre. `Out of memory` hatası alırsanız küçültün (16 → 8 → 4).\n",
    "- **imgsz**: 640 iyi bir başlangıç; hız için 480 deneyin ama doğruluk düşer.\n",
    "- **lr (learning rate)**: model.train() içine `lr` argümanı verilebilir, varsayılan genelde iyi çalışır. Eğer eğitim hızlıca plateau oluyorsa lr'yi azaltın.\n",
    "- **early stopping**: ultralytics otomatik olarak `patience` benzeri mekanizmalar kullanır; doğrulama mAP iyileşmezse `best.pt`'i kaydeder.\n",
    "- **augmentasyon**: Roboflow veya ultralytics'in `augment` parametresiyle veri augmentasyonu yapabilirsiniz.\n",
    "- **class imbalance**: Eğer `no_helmet` örnekleriniz azsa augment veya ekstra veri toplayın.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d7b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Değerlendirme ve tahmin örneği\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# en iyi ağırlığı yükle (eğitimden çıkan path farklı olabilir)\n",
    "best_weights = 'runs/train/exp/weights/best.pt'\n",
    "model = YOLO(best_weights)\n",
    "\n",
    "# Tek bir resim üzerinde test et ve sonuçları kaydet\n",
    "sample_image = '/content/dataset/val/images'  # bu klasörde en az 1 resim olmalı\n",
    "# Eğer belirli bir dosya ismi biliyorsanız onu verin, örn: '/content/dataset/val/images/img001.jpg'\n",
    "\n",
    "# Aşağıdaki predict komutu, sonuçları runs/predict/ içinde kaydeder (save=True) ve konsola özet yazdırır.\n",
    "# Eğer sample_image bir klasör ise model otomatik olarak o klasördeki resimlere çalışır.\n",
    "res = model.predict(source=sample_image, conf=0.25, imgsz=640, save=True)\n",
    "print('Tahmin tamamlandı. Kayıt yolu örnek:', res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada03a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Doğrulama (metrics)\n",
    "# ultralytics ile validation sonuçlarını almak:\n",
    "model.val()  # validation run çağırır ve mAP gibi metrikleri gösterir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Modeli ONNX'e dışa aktar\n",
    "# Bu hücre eğitim bittikten sonra çalıştırılmalı ve best.pt yolunu model dosyanıza göre güncelleyin.\n",
    "from ultralytics import YOLO\n",
    "m = YOLO('runs/train/exp/weights/best.pt')\n",
    "# Export ONNX (opset default). imgsz modelin beklediği giriş boyutu ile eşleşmeli (e.g., 640)\n",
    "m.export(format='onnx', imgsz=640)\n",
    "print('ONNX export tamamlandı — dosyayı runs/format/ altında arayın (ör: runs/format/onnx/best.onnx)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d653273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) (Opsiyonel) ONNX dynamic quantization — CPU inference hızlandırabilir\n",
    "try:\n",
    "    from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "    src = 'runs/format/onnx/best.onnx'\n",
    "    dst = 'runs/format/onnx/best_quant.onnx'\n",
    "    quantize_dynamic(src, dst, weight_type=QuantType.QInt8)\n",
    "    print('Quantization tamamlandı:', dst)\n",
    "except Exception as e:\n",
    "    print('Quantization çalıştırılamadı:', e)\n",
    "    print('ONNX quantization için onnxruntime-inference-tools gerekebilir veya dosya yollarını kontrol edin.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6469b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) ONNXRuntime ile hızlı test (basit örnek). Model çıktısı export edilmiş ONNX formatına göre değişebilir.\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "onnx_path = 'runs/format/onnx/best.onnx'\n",
    "try:\n",
    "    sess = ort.InferenceSession(onnx_path, providers=['CPUExecutionProvider'])\n",
    "    print('ONNX loaded. Inputs:', [i.name + str(tuple(i.shape)) for i in sess.get_inputs()])\n",
    "    print('Outputs:', [o.name + str(tuple(o.shape)) for o in sess.get_outputs()])\n",
    "except Exception as e:\n",
    "    print('ONNX yüklenemedi veya yol yanlış:', e)\n",
    "    print('Eğer export farklı klasöre kaydedildiyse doğru path ile güncelleyin.')\n",
    "\n",
    "# Not: ONNX çıktısının postprocess'i modelinize göre değişir. Backend içinde ONNX için özel bir pre/postprocess implementasyonu gerekecektir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5963067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Eğitilmiş ağırlıkları indirme (Colab için):\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('runs/train/exp/weights/best.pt')\n",
    "except Exception as e:\n",
    "    print('files.download çalıştırılamadı (muhtemelen Colab değil). runs/train/exp/weights/best.pt yolunu manuel olarak indirin ya da Drive a kopyalayın:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307c9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) Video üzerinde inference örneği ve snapshot kaydetme\n",
    "# Bu örnek ultralytics model objesi ile video çalıştırır; her tespitte frame'i kaydedip klasöre yazar.\n",
    "import cv2, os, json\n",
    "from pathlib import Path\n",
    "\n",
    "best = 'runs/train/exp/weights/best.pt'\n",
    "model = YOLO(best)\n",
    "\n",
    "video_path = '/content/sample_video.mp4'  # kendi videonuzun yolunu yazın\n",
    "out_dir = '/content/video_detections'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print('Video açılamadı — doğru yol verdiğinizden emin olun veya önceden bir örnek video yükleyin.')\n",
    "else:\n",
    "    frame_no = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_no += 1\n",
    "        # her n. frame üzerinde çalıştırmak isterseniz örnekleme ekleyin\n",
    "        if frame_no % 5 != 0:\n",
    "            continue\n",
    "        # ultralytics model predict için geçici dosya kullanmak hızlı ve pratik\n",
    "        tmp_path = f'/tmp/frame_{frame_no}.jpg'\n",
    "        cv2.imwrite(tmp_path, frame)\n",
    "        res = model.predict(source=tmp_path, conf=0.35, imgsz=640)\n",
    "        # res bir list-like objedir; res[0].boxes içinde tespitler vardır\n",
    "        boxes = res[0].boxes if len(res) else []\n",
    "        if len(boxes):\n",
    "            # snapshot kaydet\n",
    "            save_path = os.path.join(out_dir, f'frame_{frame_no}.jpg')\n",
    "            cv2.imwrite(save_path, frame)\n",
    "            print('Detected -> saved snapshot:', save_path)\n",
    "    cap.release()\n",
    "    print('Video inference tamamlandı. snapshot klasörü:', out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ee210",
   "metadata": {},
   "source": [
    "## Son notlar, hata ayıklama ve sonraki adımlar\n",
    "\n",
    "- Eğer `Out of memory` (OOM) hatası alırsanız: `batch` küçültün, `imgsz` küçültün (ör: 640 -> 480), veya `yolov8n` yerine daha küçük bir model kullanın.\n",
    "- Etiket formatı hataları sık yapılır — label txt'lerinin isimlerinin görüntü isimleriyle bire bir uyuştuğundan emin olun (uzantı farklı olursa hata verir).\n",
    "- ONNX export sonrası backend tarafında (FastAPI) `preprocess` ve `postprocess` fonksiyonlarını ONNX çıktı biçimine göre **özelleştirmeniz** gerekir.\n",
    "- Colab'da eğitim sırasında `runs/train/exp` dizinini inceleyin; `results.png` görselleştirmesi ve `best.pt` bu klasörde bulunur.\n",
    "\n",
    "---\n",
    "\n",
    "Eğer istersen, şimdi bu notebook'u sizin veri setinizin yollarına göre **özelleştirip** çalıştırılabilir hâle getirebilirim; ayrıca eğitilmiş `best.onnx` dosyasını backend'e taşımak için gereken `export_to_onnx.py` ve `onnx` için preprocess/postprocess örnek kodunu da hazırlayabilirim.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
